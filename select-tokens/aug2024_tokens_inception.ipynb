{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf2ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from collections import defaultdict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7767bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 957 unique ERC-20 tokens in pools created feb 2024.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "UNISWAP_V3_SUBGRAPH_URL = \"https://gateway.thegraph.com/api/214ad8fea4f34456c35952f32963b967/subgraphs/id/5zvR82QoaXYFyDEKLZ9t6v9adgnptxYpKpSbxtgVENFV\"\n",
    "\n",
    "def fetch_october_2023_tokens_from_pools():\n",
    "    query = \"\"\"\n",
    "    {\n",
    "      pools(\n",
    "        first: 1000,\n",
    "        orderBy: createdAtTimestamp,\n",
    "        orderDirection: asc,\n",
    "        where: {\n",
    "          createdAtTimestamp_gte: 1722470400,\n",
    "          createdAtTimestamp_lt:  1725148800\n",
    "        }\n",
    "      ) {\n",
    "        id\n",
    "        createdAtTimestamp\n",
    "        token0 {\n",
    "          id\n",
    "          symbol\n",
    "          name\n",
    "          decimals\n",
    "        }\n",
    "        token1 {\n",
    "          id\n",
    "          symbol\n",
    "          name\n",
    "          decimals\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.post(UNISWAP_V3_SUBGRAPH_URL, json={\"query\": query})\n",
    "    data = response.json()\n",
    "\n",
    "    if \"errors\" in data:\n",
    "        print(\"GraphQL error:\", data[\"errors\"])\n",
    "        return []\n",
    "\n",
    "    tokens = {}\n",
    "    for pool in data[\"data\"][\"pools\"]:\n",
    "        for token_key in [\"token0\", \"token1\"]:\n",
    "            token = pool[token_key]\n",
    "            tokens[token[\"id\"]] = {\n",
    "                \"address\": token[\"id\"],\n",
    "                \"symbol\": token[\"symbol\"],\n",
    "                \"name\": token[\"name\"],\n",
    "                \"decimals\": int(token[\"decimals\"])\n",
    "            }\n",
    "\n",
    "    print(f\"✅ Found {len(tokens)} unique ERC-20 tokens in pools created feb 2024.\")\n",
    "    return list(tokens.values())\n",
    "\n",
    "tokens_october = fetch_october_2023_tokens_from_pools()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edfdcc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"214ad8fea4f34456c35952f32963b967\"\n",
    "HEADERS = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "SUBGRAPH_URL = \"https://gateway.thegraph.com/api/subgraphs/id/5zvR82QoaXYFyDEKLZ9t6v9adgnptxYpKpSbxtgVENFV\"\n",
    "\n",
    "# timestamps\n",
    "START_TS = 1722470400  # august 1, 2024\n",
    "END_TS = 1725148800    # august 31, 2024\n",
    "\n",
    "def run_query(query):\n",
    "    response = requests.post(SUBGRAPH_URL, json={\"query\": query}, headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        resp_json = response.json()\n",
    "        if \"errors\" in resp_json:\n",
    "            raise Exception(f\"GraphQL errors: {resp_json['errors']}\")\n",
    "        return resp_json[\"data\"]\n",
    "    else:\n",
    "        raise Exception(f\"Query failed with status code {response.status_code}: {response.text}\")\n",
    "\n",
    "def fetch_pools_created_october():\n",
    "    pools = []\n",
    "    skip = 0\n",
    "    batch_size = 1000\n",
    "\n",
    "    while True:\n",
    "        query = f\"\"\"\n",
    "        {{\n",
    "          pools(\n",
    "            first: {batch_size},\n",
    "            skip: {skip},\n",
    "            orderBy: createdAtTimestamp,\n",
    "            orderDirection: asc,\n",
    "            where: {{\n",
    "              createdAtTimestamp_gte: {START_TS},\n",
    "              createdAtTimestamp_lt: {END_TS}\n",
    "            }}\n",
    "          ) {{\n",
    "            id\n",
    "            createdAtTimestamp\n",
    "            token0 {{\n",
    "              id\n",
    "              symbol\n",
    "              name\n",
    "              decimals\n",
    "            }}\n",
    "            token1 {{\n",
    "              id\n",
    "              symbol\n",
    "              name\n",
    "              decimals\n",
    "            }}\n",
    "          }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "        data = run_query(query)\n",
    "        batch = data[\"pools\"]\n",
    "        pools.extend(batch)\n",
    "        print(f\"Fetched {len(batch)} pools, total so far: {len(pools)}\")\n",
    "        if len(batch) < batch_size:\n",
    "            break\n",
    "        skip += batch_size\n",
    "        time.sleep(0.3)  # be gentle to API\n",
    "\n",
    "    return pools\n",
    "\n",
    "def extract_unique_tokens_from_pools(pools):\n",
    "    tokens = {}\n",
    "    for pool in pools:\n",
    "        for token_key in [\"token0\", \"token1\"]:\n",
    "            token = pool[token_key]\n",
    "            tokens[token[\"id\"]] = {\n",
    "                \"symbol\": token[\"symbol\"],\n",
    "                \"name\": token[\"name\"],\n",
    "                \"decimals\": int(token[\"decimals\"]),\n",
    "                \"address\": token[\"id\"],\n",
    "            }\n",
    "    return tokens\n",
    "\n",
    "def fetch_pool_day_data(pool_ids):\n",
    "    pool_volumes = defaultdict(float)\n",
    "    batch_size = 50\n",
    "\n",
    "    # Fetch daily volumes for each pool for October\n",
    "    for i in range(0, len(pool_ids), batch_size):\n",
    "        batch_ids = pool_ids[i : i + batch_size]\n",
    "        ids_string = ','.join(f'\"{pid}\"' for pid in batch_ids)\n",
    "\n",
    "        query = f\"\"\"\n",
    "        {{\n",
    "          poolDayDatas(\n",
    "            where: {{\n",
    "              pool_in: [{ids_string}],\n",
    "              date_gte: {START_TS},\n",
    "              date_lt: {END_TS}\n",
    "            }},\n",
    "            first: 1000\n",
    "          ) {{\n",
    "            pool {{\n",
    "              id\n",
    "              token0 {{\n",
    "                id\n",
    "                symbol\n",
    "              }}\n",
    "              token1 {{\n",
    "                id\n",
    "                symbol\n",
    "              }}\n",
    "            }}\n",
    "            volumeUSD\n",
    "            date\n",
    "          }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "        data = run_query(query)\n",
    "        day_data = data[\"poolDayDatas\"]\n",
    "\n",
    "        for record in day_data:\n",
    "            pool = record[\"pool\"]\n",
    "            vol = float(record[\"volumeUSD\"])\n",
    "            # Assign half volume to token0 and half to token1 (simplification)\n",
    "            pool_volumes[pool[\"token0\"][\"id\"]] += vol / 2\n",
    "            pool_volumes[pool[\"token1\"][\"id\"]] += vol / 2\n",
    "\n",
    "        print(f\"Processed batch {i} to {i+batch_size}, total poolDayData: {len(day_data)}\")\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    return pool_volumes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52d8d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Fetching pools created in august 2024...\")\n",
    "    pools = fetch_pools_created_october()\n",
    "    print(f\"Total pools fetched: {len(pools)}\")\n",
    "\n",
    "    print(\"Extracting unique tokens from pools...\")\n",
    "    tokens = extract_unique_tokens_from_pools(pools)\n",
    "    print(f\"Total unique tokens found: {len(tokens)}\")\n",
    "\n",
    "    pool_ids = [pool[\"id\"] for pool in pools]\n",
    "    print(f\"Fetching poolDayData for {len(pool_ids)} pools...\")\n",
    "\n",
    "    volumes = fetch_pool_day_data(pool_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5de63c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching pools created in august 2024...\n",
      "Fetched 1000 pools, total so far: 1000\n",
      "Fetched 124 pools, total so far: 1124\n",
      "Total pools fetched: 1124\n",
      "Extracting unique tokens from pools...\n",
      "Total unique tokens found: 1051\n",
      "Fetching poolDayData for 1124 pools...\n",
      "Processed batch 0 to 50, total poolDayData: 315\n",
      "Processed batch 50 to 100, total poolDayData: 205\n",
      "Processed batch 100 to 150, total poolDayData: 276\n",
      "Processed batch 150 to 200, total poolDayData: 277\n",
      "Processed batch 200 to 250, total poolDayData: 310\n",
      "Processed batch 250 to 300, total poolDayData: 224\n",
      "Processed batch 300 to 350, total poolDayData: 173\n",
      "Processed batch 350 to 400, total poolDayData: 234\n",
      "Processed batch 400 to 450, total poolDayData: 195\n",
      "Processed batch 450 to 500, total poolDayData: 195\n",
      "Processed batch 500 to 550, total poolDayData: 153\n",
      "Processed batch 550 to 600, total poolDayData: 150\n",
      "Processed batch 600 to 650, total poolDayData: 186\n",
      "Processed batch 650 to 700, total poolDayData: 151\n",
      "Processed batch 700 to 750, total poolDayData: 160\n",
      "Processed batch 750 to 800, total poolDayData: 114\n",
      "Processed batch 800 to 850, total poolDayData: 99\n",
      "Processed batch 850 to 900, total poolDayData: 114\n",
      "Processed batch 900 to 950, total poolDayData: 94\n",
      "Processed batch 950 to 1000, total poolDayData: 88\n",
      "Processed batch 1000 to 1050, total poolDayData: 77\n",
      "Processed batch 1050 to 1100, total poolDayData: 63\n",
      "Processed batch 1100 to 1150, total poolDayData: 25\n",
      "Calculated monthly volumes for 1050 tokens.\n",
      "\n",
      "Top 5 tokens by volume in august 2024:\n",
      "WETH (0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2): $63,125,801.55\n",
      "USDC (0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48): $24,804,358.13\n",
      "KOIN (0x7b0df1cd724ec34ec9bc4bd19749b01afb490761): $23,324,749.21\n",
      "USDT (0xdac17f958d2ee523a2206206994597c13d831ec7): $6,810,501.30\n",
      "GOLD (0xa78bcbb74b822e74a847897d2d1d2d5ee2c76bd8): $6,805,366.91\n",
      "\n",
      "Top 5 tokens by volume ranked 100-200:\n",
      "DMND (0x6d2060fc66fa2b619f5928ba40409a53e0bc232d): $69,076.97\n",
      "HOIN (0x9dfd0f8c4703325c7ca4c29a20930a2f350da244): $67,283.93\n",
      "fpY00TS (0x000000006aed1f173905919729e44f0d7b5c0cb7): $67,181.81\n",
      "BAPE (0x6e261d89d3d48fb151cf47e19ad7e8e8ed417145): $65,002.48\n",
      "EBULL (0x71297312753ea7a2570a5a3278ed70d9a75f4f44): $63,176.47\n",
      "\n",
      "Top 5 tokens by volume ranked 50-100:\n",
      "QAT (0xfc940b365ee4012a5821b5e9638ff36cd2af25b3): $304,735.63\n",
      "CUBE (0x73a740d256188395d9af56db31ab1e9bb2f2978d): $303,633.15\n",
      "MONOPOLY (0x7d4a7be025652995364e0e232063abd9e8d65e6e): $299,933.02\n",
      "PEEPO (0x23483a9a525cdfb1740d6f441c6a3deafa54f7aa): $297,878.15\n",
      "FUKU (0x408b7d99af8ab798c816cddb0e60901bc1ce8f3d): $295,051.58\n",
      "\n",
      "Top 20 tokens by volume in august 2024:\n",
      "WETH (0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2): $63,125,801.55\n",
      "USDC (0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48): $24,804,358.13\n",
      "KOIN (0x7b0df1cd724ec34ec9bc4bd19749b01afb490761): $23,324,749.21\n",
      "USDT (0xdac17f958d2ee523a2206206994597c13d831ec7): $6,810,501.30\n",
      "GOLD (0xa78bcbb74b822e74a847897d2d1d2d5ee2c76bd8): $6,805,366.91\n",
      "FUKU (0x1001271083c249bd771e1bb76c22d935809a61ee): $6,027,473.22\n",
      "WAI (0xfe8526a77a2c3590e5973ba81308b90bea21fbff): $4,592,451.60\n",
      "AUSD (0x00000000efe302beaa2b3e6e1b18d08d69a9012a): $3,446,812.76\n",
      "BERRY (0xcb76314c2540199f4b844d4ebbc7998c604880ca): $3,041,301.90\n",
      "POPCAT (0xdfd8e5f7ed841d76ed4b1147ea3bf9d4e94a6d69): $2,805,057.21\n",
      "SATO (0x5de758bba013e58dae2693aea3f0b12b31a3023d): $2,737,886.17\n",
      "WUKONG (0xe20b162aefd9c63bc07c48deae024221f3be0a2d): $2,070,160.77\n",
      "MAX (0xb7109df1a93f8fe2b8162c6207c9b846c1c68090): $1,724,849.75\n",
      "Neiro (0x812ba41e071c7b7fa4ebcfb62df5f45f6fa853ee): $1,705,831.18\n",
      "COLON (0xd09eb9099fac55edcbf4965e0a866779ca365a0c): $1,686,207.53\n",
      "BRUH (0xd7cfdb3cdc33dbeb9e9a4c95b61953cf12a008b3): $1,672,134.47\n",
      "ONI (0x7777cec341e7434126864195adef9b05dcc3489c): $1,466,862.72\n",
      "KABOSU (0x180000dda70eb7fb7f3e10e52e88ce88f46e3b3a): $1,438,194.12\n",
      "EBEAR (0x32ab7f30ba2152106fee3d855ae318f2b4c4e65f): $1,363,720.07\n",
      "WLFI (0xe59cd10f7f24e16e08b72a5f7dd57a4b49cd5b12): $1,075,573.77\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"Fetching pools created in august 2024...\")\n",
    "    pools = fetch_pools_created_october()\n",
    "    print(f\"Total pools fetched: {len(pools)}\")\n",
    "\n",
    "    print(\"Extracting unique tokens from pools...\")\n",
    "    tokens = extract_unique_tokens_from_pools(pools)\n",
    "    print(f\"Total unique tokens found: {len(tokens)}\")\n",
    "\n",
    "    pool_ids = [pool[\"id\"] for pool in pools]\n",
    "    print(f\"Fetching poolDayData for {len(pool_ids)} pools...\")\n",
    "\n",
    "    volumes = fetch_pool_day_data(pool_ids)\n",
    "    print(f\"Calculated monthly volumes for {len(volumes)} tokens.\")\n",
    "\n",
    "    # Sort tokens by volume descending\n",
    "    sorted_tokens = sorted(volumes.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"\\nTop 5 tokens by volume in august 2024:\")\n",
    "    for token_id, vol in sorted_tokens[:5]:\n",
    "        symbol = tokens[token_id][\"symbol\"] if token_id in tokens else \"UNKNOWN\"\n",
    "        print(f\"{symbol} ({token_id}): ${vol:,.2f}\")\n",
    "\n",
    "    # Now slice tokens ranked 100 to 199 (0-based indexing)\n",
    "    subset_tokens = sorted_tokens[100:200]\n",
    "\n",
    "    print(\"\\nTop 5 tokens by volume ranked 100-200:\")\n",
    "    for token_id, vol in subset_tokens[:5]:\n",
    "        symbol = tokens[token_id][\"symbol\"] if token_id in tokens else \"UNKNOWN\"\n",
    "        print(f\"{symbol} ({token_id}): ${vol:,.2f}\")\n",
    "\n",
    "    # Now slice tokens ranked 50 to 99 (0-based indexing)\n",
    "    subset_tokens = sorted_tokens[50:100]\n",
    "\n",
    "    print(\"\\nTop 5 tokens by volume ranked 50-100:\")\n",
    "    for token_id, vol in subset_tokens[:5]:\n",
    "        symbol = tokens[token_id][\"symbol\"] if token_id in tokens else \"UNKNOWN\"\n",
    "        print(f\"{symbol} ({token_id}): ${vol:,.2f}\")\n",
    "        \n",
    "        \n",
    "    # Sort tokens by volume descending\n",
    "    sorted_tokens = sorted(volumes.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"\\nTop 20 tokens by volume in august 2024:\")\n",
    "    for token_id, vol in sorted_tokens[:20]:\n",
    "        symbol = tokens[token_id][\"symbol\"] if token_id in tokens else \"UNKNOWN\"\n",
    "        print(f\"{symbol} ({token_id}): ${vol:,.2f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bafd9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
