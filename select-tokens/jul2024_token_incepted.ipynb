{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "585b7677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from collections import defaultdict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9445f985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 906 unique ERC-20 tokens in pools created feb 2024.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "UNISWAP_V3_SUBGRAPH_URL = \"https://gateway.thegraph.com/api/214ad8fea4f34456c35952f32963b967/subgraphs/id/5zvR82QoaXYFyDEKLZ9t6v9adgnptxYpKpSbxtgVENFV\"\n",
    "\n",
    "def fetch_october_2023_tokens_from_pools():\n",
    "    query = \"\"\"\n",
    "    {\n",
    "      pools(\n",
    "        first: 1000,\n",
    "        orderBy: createdAtTimestamp,\n",
    "        orderDirection: asc,\n",
    "        where: {\n",
    "          createdAtTimestamp_gte: 1719792000,\n",
    "          createdAtTimestamp_lt:  1722470400\n",
    "        }\n",
    "      ) {\n",
    "        id\n",
    "        createdAtTimestamp\n",
    "        token0 {\n",
    "          id\n",
    "          symbol\n",
    "          name\n",
    "          decimals\n",
    "        }\n",
    "        token1 {\n",
    "          id\n",
    "          symbol\n",
    "          name\n",
    "          decimals\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.post(UNISWAP_V3_SUBGRAPH_URL, json={\"query\": query})\n",
    "    data = response.json()\n",
    "\n",
    "    if \"errors\" in data:\n",
    "        print(\"GraphQL error:\", data[\"errors\"])\n",
    "        return []\n",
    "\n",
    "    tokens = {}\n",
    "    for pool in data[\"data\"][\"pools\"]:\n",
    "        for token_key in [\"token0\", \"token1\"]:\n",
    "            token = pool[token_key]\n",
    "            tokens[token[\"id\"]] = {\n",
    "                \"address\": token[\"id\"],\n",
    "                \"symbol\": token[\"symbol\"],\n",
    "                \"name\": token[\"name\"],\n",
    "                \"decimals\": int(token[\"decimals\"])\n",
    "            }\n",
    "\n",
    "    print(f\"✅ Found {len(tokens)} unique ERC-20 tokens in pools created feb 2024.\")\n",
    "    return list(tokens.values())\n",
    "\n",
    "tokens_october = fetch_october_2023_tokens_from_pools()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33afd8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"214ad8fea4f34456c35952f32963b967\"\n",
    "HEADERS = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "SUBGRAPH_URL = \"https://gateway.thegraph.com/api/subgraphs/id/5zvR82QoaXYFyDEKLZ9t6v9adgnptxYpKpSbxtgVENFV\"\n",
    "\n",
    "# timestamps\n",
    "START_TS = 1719792000  # july 1, 2024\n",
    "END_TS = 1722470400    # july 31, 2024\n",
    "\n",
    "def run_query(query):\n",
    "    response = requests.post(SUBGRAPH_URL, json={\"query\": query}, headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        resp_json = response.json()\n",
    "        if \"errors\" in resp_json:\n",
    "            raise Exception(f\"GraphQL errors: {resp_json['errors']}\")\n",
    "        return resp_json[\"data\"]\n",
    "    else:\n",
    "        raise Exception(f\"Query failed with status code {response.status_code}: {response.text}\")\n",
    "\n",
    "def fetch_pools_created_october():\n",
    "    pools = []\n",
    "    skip = 0\n",
    "    batch_size = 1000\n",
    "\n",
    "    while True:\n",
    "        query = f\"\"\"\n",
    "        {{\n",
    "          pools(\n",
    "            first: {batch_size},\n",
    "            skip: {skip},\n",
    "            orderBy: createdAtTimestamp,\n",
    "            orderDirection: asc,\n",
    "            where: {{\n",
    "              createdAtTimestamp_gte: {START_TS},\n",
    "              createdAtTimestamp_lt: {END_TS}\n",
    "            }}\n",
    "          ) {{\n",
    "            id\n",
    "            createdAtTimestamp\n",
    "            token0 {{\n",
    "              id\n",
    "              symbol\n",
    "              name\n",
    "              decimals\n",
    "            }}\n",
    "            token1 {{\n",
    "              id\n",
    "              symbol\n",
    "              name\n",
    "              decimals\n",
    "            }}\n",
    "          }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "        data = run_query(query)\n",
    "        batch = data[\"pools\"]\n",
    "        pools.extend(batch)\n",
    "        print(f\"Fetched {len(batch)} pools, total so far: {len(pools)}\")\n",
    "        if len(batch) < batch_size:\n",
    "            break\n",
    "        skip += batch_size\n",
    "        time.sleep(0.3)  # be gentle to API\n",
    "\n",
    "    return pools\n",
    "\n",
    "def extract_unique_tokens_from_pools(pools):\n",
    "    tokens = {}\n",
    "    for pool in pools:\n",
    "        for token_key in [\"token0\", \"token1\"]:\n",
    "            token = pool[token_key]\n",
    "            tokens[token[\"id\"]] = {\n",
    "                \"symbol\": token[\"symbol\"],\n",
    "                \"name\": token[\"name\"],\n",
    "                \"decimals\": int(token[\"decimals\"]),\n",
    "                \"address\": token[\"id\"],\n",
    "            }\n",
    "    return tokens\n",
    "\n",
    "def fetch_pool_day_data(pool_ids):\n",
    "    pool_volumes = defaultdict(float)\n",
    "    batch_size = 50\n",
    "\n",
    "    # Fetch daily volumes for each pool for October\n",
    "    for i in range(0, len(pool_ids), batch_size):\n",
    "        batch_ids = pool_ids[i : i + batch_size]\n",
    "        ids_string = ','.join(f'\"{pid}\"' for pid in batch_ids)\n",
    "\n",
    "        query = f\"\"\"\n",
    "        {{\n",
    "          poolDayDatas(\n",
    "            where: {{\n",
    "              pool_in: [{ids_string}],\n",
    "              date_gte: {START_TS},\n",
    "              date_lt: {END_TS}\n",
    "            }},\n",
    "            first: 1000\n",
    "          ) {{\n",
    "            pool {{\n",
    "              id\n",
    "              token0 {{\n",
    "                id\n",
    "                symbol\n",
    "              }}\n",
    "              token1 {{\n",
    "                id\n",
    "                symbol\n",
    "              }}\n",
    "            }}\n",
    "            volumeUSD\n",
    "            date\n",
    "          }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "        data = run_query(query)\n",
    "        day_data = data[\"poolDayDatas\"]\n",
    "\n",
    "        for record in day_data:\n",
    "            pool = record[\"pool\"]\n",
    "            vol = float(record[\"volumeUSD\"])\n",
    "            # Assign half volume to token0 and half to token1 (simplification)\n",
    "            pool_volumes[pool[\"token0\"][\"id\"]] += vol / 2\n",
    "            pool_volumes[pool[\"token1\"][\"id\"]] += vol / 2\n",
    "\n",
    "        print(f\"Processed batch {i} to {i+batch_size}, total poolDayData: {len(day_data)}\")\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    return pool_volumes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c979ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Fetching pools created in july 2024...\")\n",
    "    pools = fetch_pools_created_october()\n",
    "    print(f\"Total pools fetched: {len(pools)}\")\n",
    "\n",
    "    print(\"Extracting unique tokens from pools...\")\n",
    "    tokens = extract_unique_tokens_from_pools(pools)\n",
    "    print(f\"Total unique tokens found: {len(tokens)}\")\n",
    "\n",
    "    pool_ids = [pool[\"id\"] for pool in pools]\n",
    "    print(f\"Fetching poolDayData for {len(pool_ids)} pools...\")\n",
    "\n",
    "    volumes = fetch_pool_day_data(pool_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "817cda8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching pools created in july 2024...\n",
      "Fetched 1000 pools, total so far: 1000\n",
      "Fetched 29 pools, total so far: 1029\n",
      "Total pools fetched: 1029\n",
      "Extracting unique tokens from pools...\n",
      "Total unique tokens found: 930\n",
      "Fetching poolDayData for 1029 pools...\n",
      "Processed batch 0 to 50, total poolDayData: 122\n",
      "Processed batch 50 to 100, total poolDayData: 288\n",
      "Processed batch 100 to 150, total poolDayData: 429\n",
      "Processed batch 150 to 200, total poolDayData: 282\n",
      "Processed batch 200 to 250, total poolDayData: 262\n",
      "Processed batch 250 to 300, total poolDayData: 198\n",
      "Processed batch 300 to 350, total poolDayData: 208\n",
      "Processed batch 350 to 400, total poolDayData: 215\n",
      "Processed batch 400 to 450, total poolDayData: 186\n",
      "Processed batch 450 to 500, total poolDayData: 134\n",
      "Processed batch 500 to 550, total poolDayData: 129\n",
      "Processed batch 550 to 600, total poolDayData: 161\n",
      "Processed batch 600 to 650, total poolDayData: 128\n",
      "Processed batch 650 to 700, total poolDayData: 114\n",
      "Processed batch 700 to 750, total poolDayData: 162\n",
      "Processed batch 750 to 800, total poolDayData: 142\n",
      "Processed batch 800 to 850, total poolDayData: 124\n",
      "Processed batch 850 to 900, total poolDayData: 119\n",
      "Processed batch 900 to 950, total poolDayData: 99\n",
      "Processed batch 950 to 1000, total poolDayData: 62\n",
      "Processed batch 1000 to 1050, total poolDayData: 29\n",
      "Calculated monthly volumes for 927 tokens.\n",
      "\n",
      "Top 5 tokens by volume in july 2024:\n",
      "WETH (0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2): $163,976,531.86\n",
      "FIGHT (0x8802269d1283cdb2a5a329649e5cb4cdcee91ab6): $36,848,314.28\n",
      "NEIRO (0xee2a03aa6dacf51c18679c516ad5283d8e7c2637): $18,304,753.53\n",
      "USDT (0xdac17f958d2ee523a2206206994597c13d831ec7): $9,911,506.28\n",
      "MAPE (0x683a4ac99e65200921f556a19dadf4b0214b5938): $8,213,638.30\n",
      "\n",
      "Top 5 tokens by volume ranked 100-200:\n",
      "Zorro (0x543d394796b879ff121f3760756ff60ea4a6e1b5): $202,449.12\n",
      "EUUS (0x735acdedd91a80334ff72f07bff41e1eecf26677): $201,895.15\n",
      "FATT (0xe0db15fdd492780d070aa7da6747e795d626bc25): $201,283.23\n",
      "RORY (0x341fbd869edbfe5e2e96a36d735482025612b348): $189,503.65\n",
      "$NTMPI (0x53be7be0ce7f92bcbd2138305735160fb799be4f): $183,344.48\n",
      "\n",
      "Top 5 tokens by volume ranked 50-100:\n",
      "USPEPE (0x07040971246a73ebda9cf29ea1306bb47c7c4e76): $591,709.90\n",
      "WBTC (0x2260fac5e5542a773aa44fbcfedf7c193bc2c599): $577,298.81\n",
      "HoldyDog (0xa9492900b8917cb6350a7a3e4c5ca223edaa3112): $563,264.23\n",
      "WWNF (0xc8cb382ee74182742f6f89367dc34b74d61fe174): $518,297.71\n",
      "apetardio (0x0a6fe4b6eef3775c61b79f0d3bc1bb6e3014c37b): $517,577.68\n",
      "\n",
      "Top 20 tokens by volume in july 2024:\n",
      "WETH (0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2): $163,976,531.86\n",
      "FIGHT (0x8802269d1283cdb2a5a329649e5cb4cdcee91ab6): $36,848,314.28\n",
      "NEIRO (0xee2a03aa6dacf51c18679c516ad5283d8e7c2637): $18,304,753.53\n",
      "USDT (0xdac17f958d2ee523a2206206994597c13d831ec7): $9,911,506.28\n",
      "MAPE (0x683a4ac99e65200921f556a19dadf4b0214b5938): $8,213,638.30\n",
      "MOYA (0x620aa20875ec1144126ea47fb27ecfe6e10d0c56): $6,219,132.03\n",
      "TRUMPMANIA (0xe39f5c9b6a9c225a50e1bb3b83649ae85bdf0591): $6,069,564.69\n",
      "TRUMP (0xfd21f17f98ac24e88180d541e685d6bd889eb6e8): $5,915,705.14\n",
      "TRUMPMANIA (0xcaf06cd34acfa9664fa68982d8f17740711e0988): $5,448,551.06\n",
      "DINERO (0x6df0e641fc9847c0c6fde39be6253045440c14d3): $5,081,100.54\n",
      "USDC (0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48): $5,052,532.98\n",
      "DOP (0x97a9a15168c22b3c137e6381037e1499c8ad0978): $3,886,330.54\n",
      "WWBM (0xfc64cb43fe6c60f6df6a0eaaf0e5bb6686cdd068): $3,808,814.95\n",
      "HARRIS (0x89a1248d11d3a541cab0f7bc988a81d68881426e): $3,712,134.17\n",
      "TRUMP (0x39af68d946ecdef73bbc1a29e10e8f2ce7ae6475): $3,112,705.60\n",
      "TARD (0x58132486f5c8756860209d01c584c0af92f163a2): $3,056,938.89\n",
      "BAYC (0x28c3501fd8a248c6ac334c065fe7907062953cfd): $2,923,481.03\n",
      "HARRIS (0x155788dd4b3ccd955a5b2d461c7d6504f83f71fa): $2,773,058.89\n",
      "STEVE (0x6e068796ba34613eb9b285affe0283fef3f4d66f): $2,743,063.49\n",
      "BAR (0x777be1c6075c20184c4fd76344b7b0b7c858fe6b): $2,462,980.19\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"Fetching pools created in july 2024...\")\n",
    "    pools = fetch_pools_created_october()\n",
    "    print(f\"Total pools fetched: {len(pools)}\")\n",
    "\n",
    "    print(\"Extracting unique tokens from pools...\")\n",
    "    tokens = extract_unique_tokens_from_pools(pools)\n",
    "    print(f\"Total unique tokens found: {len(tokens)}\")\n",
    "\n",
    "    pool_ids = [pool[\"id\"] for pool in pools]\n",
    "    print(f\"Fetching poolDayData for {len(pool_ids)} pools...\")\n",
    "\n",
    "    volumes = fetch_pool_day_data(pool_ids)\n",
    "    print(f\"Calculated monthly volumes for {len(volumes)} tokens.\")\n",
    "\n",
    "    # Sort tokens by volume descending\n",
    "    sorted_tokens = sorted(volumes.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"\\nTop 5 tokens by volume in july 2024:\")\n",
    "    for token_id, vol in sorted_tokens[:5]:\n",
    "        symbol = tokens[token_id][\"symbol\"] if token_id in tokens else \"UNKNOWN\"\n",
    "        print(f\"{symbol} ({token_id}): ${vol:,.2f}\")\n",
    "\n",
    "    # Now slice tokens ranked 100 to 199 (0-based indexing)\n",
    "    subset_tokens = sorted_tokens[100:200]\n",
    "\n",
    "    print(\"\\nTop 5 tokens by volume ranked 100-200:\")\n",
    "    for token_id, vol in subset_tokens[:5]:\n",
    "        symbol = tokens[token_id][\"symbol\"] if token_id in tokens else \"UNKNOWN\"\n",
    "        print(f\"{symbol} ({token_id}): ${vol:,.2f}\")\n",
    "\n",
    "    # Now slice tokens ranked 50 to 99 (0-based indexing)\n",
    "    subset_tokens = sorted_tokens[50:100]\n",
    "\n",
    "    print(\"\\nTop 5 tokens by volume ranked 50-100:\")\n",
    "    for token_id, vol in subset_tokens[:5]:\n",
    "        symbol = tokens[token_id][\"symbol\"] if token_id in tokens else \"UNKNOWN\"\n",
    "        print(f\"{symbol} ({token_id}): ${vol:,.2f}\")\n",
    "        \n",
    "        \n",
    "    # Sort tokens by volume descending\n",
    "    sorted_tokens = sorted(volumes.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"\\nTop 20 tokens by volume in july 2024:\")\n",
    "    for token_id, vol in sorted_tokens[:20]:\n",
    "        symbol = tokens[token_id][\"symbol\"] if token_id in tokens else \"UNKNOWN\"\n",
    "        print(f\"{symbol} ({token_id}): ${vol:,.2f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b53e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
