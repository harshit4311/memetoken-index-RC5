{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e2cd971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from collections import defaultdict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b495749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 950 unique ERC-20 tokens in pools created feb 2024.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "UNISWAP_V3_SUBGRAPH_URL = \"https://gateway.thegraph.com/api/214ad8fea4f34456c35952f32963b967/subgraphs/id/5zvR82QoaXYFyDEKLZ9t6v9adgnptxYpKpSbxtgVENFV\"\n",
    "\n",
    "def fetch_october_2023_tokens_from_pools():\n",
    "    query = \"\"\"\n",
    "    {\n",
    "      pools(\n",
    "        first: 1000,\n",
    "        orderBy: createdAtTimestamp,\n",
    "        orderDirection: asc,\n",
    "        where: {\n",
    "          createdAtTimestamp_gte: 1706745600,\n",
    "          createdAtTimestamp_lt:  1709164800\n",
    "        }\n",
    "      ) {\n",
    "        id\n",
    "        createdAtTimestamp\n",
    "        token0 {\n",
    "          id\n",
    "          symbol\n",
    "          name\n",
    "          decimals\n",
    "        }\n",
    "        token1 {\n",
    "          id\n",
    "          symbol\n",
    "          name\n",
    "          decimals\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.post(UNISWAP_V3_SUBGRAPH_URL, json={\"query\": query})\n",
    "    data = response.json()\n",
    "\n",
    "    if \"errors\" in data:\n",
    "        print(\"GraphQL error:\", data[\"errors\"])\n",
    "        return []\n",
    "\n",
    "    tokens = {}\n",
    "    for pool in data[\"data\"][\"pools\"]:\n",
    "        for token_key in [\"token0\", \"token1\"]:\n",
    "            token = pool[token_key]\n",
    "            tokens[token[\"id\"]] = {\n",
    "                \"address\": token[\"id\"],\n",
    "                \"symbol\": token[\"symbol\"],\n",
    "                \"name\": token[\"name\"],\n",
    "                \"decimals\": int(token[\"decimals\"])\n",
    "            }\n",
    "\n",
    "    print(f\"✅ Found {len(tokens)} unique ERC-20 tokens in pools created feb 2024.\")\n",
    "    return list(tokens.values())\n",
    "\n",
    "tokens_october = fetch_october_2023_tokens_from_pools()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a10cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"214ad8fea4f34456c35952f32963b967\"\n",
    "HEADERS = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "SUBGRAPH_URL = \"https://gateway.thegraph.com/api/subgraphs/id/5zvR82QoaXYFyDEKLZ9t6v9adgnptxYpKpSbxtgVENFV\"\n",
    "\n",
    "# timestamps\n",
    "START_TS = 1706745600  # fev 1, 2024\n",
    "END_TS = 1709164800    # feb 29, 2024\n",
    "\n",
    "def run_query(query):\n",
    "    response = requests.post(SUBGRAPH_URL, json={\"query\": query}, headers=HEADERS)\n",
    "    if response.status_code == 200:\n",
    "        resp_json = response.json()\n",
    "        if \"errors\" in resp_json:\n",
    "            raise Exception(f\"GraphQL errors: {resp_json['errors']}\")\n",
    "        return resp_json[\"data\"]\n",
    "    else:\n",
    "        raise Exception(f\"Query failed with status code {response.status_code}: {response.text}\")\n",
    "\n",
    "def fetch_pools_created_october():\n",
    "    pools = []\n",
    "    skip = 0\n",
    "    batch_size = 1000\n",
    "\n",
    "    while True:\n",
    "        query = f\"\"\"\n",
    "        {{\n",
    "          pools(\n",
    "            first: {batch_size},\n",
    "            skip: {skip},\n",
    "            orderBy: createdAtTimestamp,\n",
    "            orderDirection: asc,\n",
    "            where: {{\n",
    "              createdAtTimestamp_gte: {START_TS},\n",
    "              createdAtTimestamp_lt: {END_TS}\n",
    "            }}\n",
    "          ) {{\n",
    "            id\n",
    "            createdAtTimestamp\n",
    "            token0 {{\n",
    "              id\n",
    "              symbol\n",
    "              name\n",
    "              decimals\n",
    "            }}\n",
    "            token1 {{\n",
    "              id\n",
    "              symbol\n",
    "              name\n",
    "              decimals\n",
    "            }}\n",
    "          }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "        data = run_query(query)\n",
    "        batch = data[\"pools\"]\n",
    "        pools.extend(batch)\n",
    "        print(f\"Fetched {len(batch)} pools, total so far: {len(pools)}\")\n",
    "        if len(batch) < batch_size:\n",
    "            break\n",
    "        skip += batch_size\n",
    "        time.sleep(0.3)  # be gentle to API\n",
    "\n",
    "    return pools\n",
    "\n",
    "def extract_unique_tokens_from_pools(pools):\n",
    "    tokens = {}\n",
    "    for pool in pools:\n",
    "        for token_key in [\"token0\", \"token1\"]:\n",
    "            token = pool[token_key]\n",
    "            tokens[token[\"id\"]] = {\n",
    "                \"symbol\": token[\"symbol\"],\n",
    "                \"name\": token[\"name\"],\n",
    "                \"decimals\": int(token[\"decimals\"]),\n",
    "                \"address\": token[\"id\"],\n",
    "            }\n",
    "    return tokens\n",
    "\n",
    "def fetch_pool_day_data(pool_ids):\n",
    "    pool_volumes = defaultdict(float)\n",
    "    batch_size = 50\n",
    "\n",
    "    # Fetch daily volumes for each pool for October\n",
    "    for i in range(0, len(pool_ids), batch_size):\n",
    "        batch_ids = pool_ids[i : i + batch_size]\n",
    "        ids_string = ','.join(f'\"{pid}\"' for pid in batch_ids)\n",
    "\n",
    "        query = f\"\"\"\n",
    "        {{\n",
    "          poolDayDatas(\n",
    "            where: {{\n",
    "              pool_in: [{ids_string}],\n",
    "              date_gte: {START_TS},\n",
    "              date_lt: {END_TS}\n",
    "            }},\n",
    "            first: 1000\n",
    "          ) {{\n",
    "            pool {{\n",
    "              id\n",
    "              token0 {{\n",
    "                id\n",
    "                symbol\n",
    "              }}\n",
    "              token1 {{\n",
    "                id\n",
    "                symbol\n",
    "              }}\n",
    "            }}\n",
    "            volumeUSD\n",
    "            date\n",
    "          }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "        data = run_query(query)\n",
    "        day_data = data[\"poolDayDatas\"]\n",
    "\n",
    "        for record in day_data:\n",
    "            pool = record[\"pool\"]\n",
    "            vol = float(record[\"volumeUSD\"])\n",
    "            # Assign half volume to token0 and half to token1 (simplification)\n",
    "            pool_volumes[pool[\"token0\"][\"id\"]] += vol / 2\n",
    "            pool_volumes[pool[\"token1\"][\"id\"]] += vol / 2\n",
    "\n",
    "        print(f\"Processed batch {i} to {i+batch_size}, total poolDayData: {len(day_data)}\")\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    return pool_volumes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee327699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Fetching pools created in feb 2024...\")\n",
    "    pools = fetch_pools_created_october()\n",
    "    print(f\"Total pools fetched: {len(pools)}\")\n",
    "\n",
    "    print(\"Extracting unique tokens from pools...\")\n",
    "    tokens = extract_unique_tokens_from_pools(pools)\n",
    "    print(f\"Total unique tokens found: {len(tokens)}\")\n",
    "\n",
    "    pool_ids = [pool[\"id\"] for pool in pools]\n",
    "    print(f\"Fetching poolDayData for {len(pool_ids)} pools...\")\n",
    "\n",
    "    volumes = fetch_pool_day_data(pool_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c5d1bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching pools created in feb 2024...\n",
      "Fetched 1000 pools, total so far: 1000\n",
      "Fetched 398 pools, total so far: 1398\n",
      "Total pools fetched: 1398\n",
      "Extracting unique tokens from pools...\n",
      "Total unique tokens found: 1308\n",
      "Fetching poolDayData for 1398 pools...\n",
      "Processed batch 0 to 50, total poolDayData: 296\n",
      "Processed batch 50 to 100, total poolDayData: 397\n",
      "Processed batch 100 to 150, total poolDayData: 248\n",
      "Processed batch 150 to 200, total poolDayData: 305\n",
      "Processed batch 200 to 250, total poolDayData: 354\n",
      "Processed batch 250 to 300, total poolDayData: 249\n",
      "Processed batch 300 to 350, total poolDayData: 190\n",
      "Processed batch 350 to 400, total poolDayData: 212\n",
      "Processed batch 400 to 450, total poolDayData: 156\n",
      "Processed batch 450 to 500, total poolDayData: 170\n",
      "Processed batch 500 to 550, total poolDayData: 212\n",
      "Processed batch 550 to 600, total poolDayData: 173\n",
      "Processed batch 600 to 650, total poolDayData: 221\n",
      "Processed batch 650 to 700, total poolDayData: 111\n",
      "Processed batch 700 to 750, total poolDayData: 139\n",
      "Processed batch 750 to 800, total poolDayData: 194\n",
      "Processed batch 800 to 850, total poolDayData: 137\n",
      "Processed batch 850 to 900, total poolDayData: 157\n",
      "Processed batch 900 to 950, total poolDayData: 178\n",
      "Processed batch 950 to 1000, total poolDayData: 155\n",
      "Processed batch 1000 to 1050, total poolDayData: 167\n",
      "Processed batch 1050 to 1100, total poolDayData: 183\n",
      "Processed batch 1100 to 1150, total poolDayData: 146\n",
      "Processed batch 1150 to 1200, total poolDayData: 156\n",
      "Processed batch 1200 to 1250, total poolDayData: 170\n",
      "Processed batch 1250 to 1300, total poolDayData: 113\n",
      "Processed batch 1300 to 1350, total poolDayData: 93\n",
      "Processed batch 1350 to 1400, total poolDayData: 51\n",
      "Calculated monthly volumes for 1283 tokens.\n",
      "\n",
      "Top 5 tokens by volume in feb 2024:\n",
      "WETH (0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2): $1,134,977,764.78\n",
      "PANDORA (0x9e9fbde7c7a83c43913bddc8779158f1368f0413): $387,689,753.56\n",
      "MAVIA (0x24fcfc492c1393274b6bcd568ac9e225bec93584): $62,017,448.77\n",
      "ALPHABET (0x038ed1383763d704d4271fe856ac96b4557e9d06): $51,576,929.29\n",
      "MNRCH (0x6c061d18d2b5bbfbe8a8d1eeb9ee27efd544cc5d): $35,323,764.28\n",
      "\n",
      "Top 5 tokens by volume ranked 100-200:\n",
      "FWIF (0xaac9f0c3fb7f4c3ac88340018da6aa81b02d5229): $1,096,367.01\n",
      "KEYS (0x16f354df8eac5b65ca51a2e30182efc0b5162521): $1,085,227.04\n",
      "BAKE (0x44face2e310e543f6d85867eb06fb251e3bfe1fc): $1,082,057.46\n",
      "NAVI (0xfc1c93a2507975e98b9d0e9260ded61a00152bf1): $992,527.99\n",
      "BLUE (0x95d8bf2f57cf973251972b496dc6b1d9c6b5bce3): $964,859.42\n",
      "\n",
      "Top 5 tokens by volume ranked 50-100:\n",
      "PLT (0x817f772398fe3d804ecfd418b944eab7ce662ca3): $4,005,994.90\n",
      "EGGX (0xe2f95ee8b72ffed59bc4d2f35b1d19b909a6e6b3): $3,921,774.67\n",
      "LOCK (0x922d8563631b03c2c4cf817f4d18f6883aba0109): $3,899,261.86\n",
      "OCH (0x19373ecbb4b8cc2253d70f2a246fa299303227ba): $3,763,177.21\n",
      "PIXEL (0x3429d03c6f7521aec737a0bbf2e5ddcef2c3ae31): $3,503,594.43\n",
      "\n",
      "Top 20 tokens by volume in feb 2024:\n",
      "WETH (0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2): $1,134,977,764.78\n",
      "PANDORA (0x9e9fbde7c7a83c43913bddc8779158f1368f0413): $387,689,753.56\n",
      "MAVIA (0x24fcfc492c1393274b6bcd568ac9e225bec93584): $62,017,448.77\n",
      "ALPHABET (0x038ed1383763d704d4271fe856ac96b4557e9d06): $51,576,929.29\n",
      "MNRCH (0x6c061d18d2b5bbfbe8a8d1eeb9ee27efd544cc5d): $35,323,764.28\n",
      "MOBY (0x40a7df3df8b56147b781353d379cb960120211d7): $23,411,047.26\n",
      "EMERALD (0x382edfe4c6168858c81893fe00fcb7b68914d929): $23,260,740.24\n",
      "pufETH (0xd9a442856c234a39a81a089c06451ebaa4306a72): $23,079,364.09\n",
      "USDC (0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48): $23,044,991.36\n",
      "MINER (0xe77ec1bf3a5c95bfe3be7bdbacfe3ac1c7e454cd): $22,696,926.39\n",
      "ANON (0x1f0efa15e9cb7ea9596257da63fecc36ba469b30): $20,999,035.25\n",
      "RUG (0xbe33f57f41a20b2f00dec91dcc1169597f36221f): $20,527,419.34\n",
      "SORA (0xb8a87405d9a4f2f866319b77004e88dff66c0d92): $20,380,722.99\n",
      "wCOMAI (0xc78b628b060258300218740b1a7a5b3c82b3bd9f): $17,686,875.69\n",
      "DEVVE (0x8248270620aa532e4d64316017be5e873e37cc09): $16,994,642.18\n",
      "wCELL (0x18e5f92103d1b34623738ee79214b1659f2ee109): $16,680,960.76\n",
      "PLT (0x553afe6468949e0685959022217336717df5fbe8): $15,539,768.17\n",
      "SHEB (0x5de869e3e62b0fb2c15573246ba3bb3fd97a2275): $14,280,218.86\n",
      "ROCK (0xb5c457ddb4ce3312a6c5a2b056a1652bd542a208): $12,965,359.53\n",
      "FORGE (0x73576a927cd93a578a9dfd61c75671d97c779da7): $11,793,650.72\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"Fetching pools created in feb 2024...\")\n",
    "    pools = fetch_pools_created_october()\n",
    "    print(f\"Total pools fetched: {len(pools)}\")\n",
    "\n",
    "    print(\"Extracting unique tokens from pools...\")\n",
    "    tokens = extract_unique_tokens_from_pools(pools)\n",
    "    print(f\"Total unique tokens found: {len(tokens)}\")\n",
    "\n",
    "    pool_ids = [pool[\"id\"] for pool in pools]\n",
    "    print(f\"Fetching poolDayData for {len(pool_ids)} pools...\")\n",
    "\n",
    "    volumes = fetch_pool_day_data(pool_ids)\n",
    "    print(f\"Calculated monthly volumes for {len(volumes)} tokens.\")\n",
    "\n",
    "    # Sort tokens by volume descending\n",
    "    sorted_tokens = sorted(volumes.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"\\nTop 5 tokens by volume in feb 2024:\")\n",
    "    for token_id, vol in sorted_tokens[:5]:\n",
    "        symbol = tokens[token_id][\"symbol\"] if token_id in tokens else \"UNKNOWN\"\n",
    "        print(f\"{symbol} ({token_id}): ${vol:,.2f}\")\n",
    "\n",
    "    # Now slice tokens ranked 100 to 199 (0-based indexing)\n",
    "    subset_tokens = sorted_tokens[100:200]\n",
    "\n",
    "    print(\"\\nTop 5 tokens by volume ranked 100-200:\")\n",
    "    for token_id, vol in subset_tokens[:5]:\n",
    "        symbol = tokens[token_id][\"symbol\"] if token_id in tokens else \"UNKNOWN\"\n",
    "        print(f\"{symbol} ({token_id}): ${vol:,.2f}\")\n",
    "\n",
    "    # Now slice tokens ranked 50 to 99 (0-based indexing)\n",
    "    subset_tokens = sorted_tokens[50:100]\n",
    "\n",
    "    print(\"\\nTop 5 tokens by volume ranked 50-100:\")\n",
    "    for token_id, vol in subset_tokens[:5]:\n",
    "        symbol = tokens[token_id][\"symbol\"] if token_id in tokens else \"UNKNOWN\"\n",
    "        print(f\"{symbol} ({token_id}): ${vol:,.2f}\")\n",
    "        \n",
    "        \n",
    "    # Sort tokens by volume descending\n",
    "    sorted_tokens = sorted(volumes.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"\\nTop 20 tokens by volume in feb 2024:\")\n",
    "    for token_id, vol in sorted_tokens[:20]:\n",
    "        symbol = tokens[token_id][\"symbol\"] if token_id in tokens else \"UNKNOWN\"\n",
    "        print(f\"{symbol} ({token_id}): ${vol:,.2f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a1fa60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
